{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "\n",
    "class ProbabilisticSampling:\n",
    "    def build_equiv_rel(self, datas, fd):\n",
    "        epsilon = {}\n",
    "        for attr in range(len(datas[0])):\n",
    "            epsilon[attr] = {}\n",
    "\n",
    "        #work on left fd\n",
    "        for i in fds[:, 0]:\n",
    "            dict = {}\n",
    "            attData = datas[:,i]\n",
    "            for j, d in enumerate(attData):\n",
    "                if not dict:\n",
    "                    dict[d] = {j}\n",
    "                else:\n",
    "                    if d not in dict:\n",
    "                        dict[d] = {j}\n",
    "                    else:\n",
    "                        dict[d].add(j)\n",
    "            epsilon[i] = dict\n",
    "\n",
    "        #work on right fd\n",
    "        fdRight = set()\n",
    "        for (left, right) in fds:\n",
    "            fdRight.add(right)\n",
    "            dict = {}\n",
    "            for val in epsilon[left]:\n",
    "                if val and val != -1:\n",
    "                    key = \"v\" + str(left) + str(val)\n",
    "                    if len(epsilon[left][val]) > 0:\n",
    "                        for idx in epsilon[left][val]:\n",
    "                            if not dict:\n",
    "                                dict[key] = {idx}\n",
    "                            else:\n",
    "                                if key not in dict:\n",
    "                                    dict[key] = {idx}\n",
    "                                else:\n",
    "                                    dict[key].add(idx)\n",
    "                    if dict:\n",
    "                        if key not in epsilon[right]:\n",
    "                            epsilon[right][key] = dict[key]\n",
    "\n",
    "        tmplist = []\n",
    "        right_dict = {}\n",
    "        for r in fdRight:\n",
    "            arr = epsilon[r].values()\n",
    "            arr = list(arr)\n",
    "            for i in range(len(arr)-1):\n",
    "                for j in range(1, len(arr)):\n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    if arr[i] and any(val in arr[j] for val in arr[i] if arr[j]):\n",
    "                        arr[j] |= set(arr[i])\n",
    "                        arr[i] = None\n",
    "\n",
    "            combined_eq_rel_indices = [a for a in arr if a is not None]\n",
    "\n",
    "            sequential_no = 0\n",
    "            for i, each_set in enumerate(combined_eq_rel_indices):\n",
    "                realvalue = datas[random.sample(each_set, 1)[0]][r]\n",
    "                use_real_value = True\n",
    "                for row_index in each_set:\n",
    "                    if realvalue != datas[row_index][r]:\n",
    "                        use_real_value = False\n",
    "                        break\n",
    "\n",
    "                key = \"\"\n",
    "\n",
    "                if use_real_value and realvalue != None:\n",
    "                    key = realvalue\n",
    "                else:\n",
    "                    key = \"v\" + str(sequential_no)\n",
    "                    sequential_no += 1\n",
    "\n",
    "                right_dict[key] = each_set\n",
    "            epsilon[r] = right_dict\n",
    "            right_dict = {}\n",
    "        return epsilon\n",
    "\n",
    "    def is_clean(self, instance, epsilon):\n",
    "        clean = True\n",
    "        for attr in epsilon:\n",
    "            for key in epsilon[attr].keys():\n",
    "                if key and 'v' in key and len(epsilon[attr][key]) > 1:\n",
    "                    return False\n",
    "        return clean\n",
    "    \n",
    "    def gen_repair(self, instance, fds):\n",
    "        cleancells = np.full([len(instance), len(instance[0])], None)\n",
    "\n",
    "        no_of_val = 1\n",
    "\n",
    "    #     Generate set indices\n",
    "        index_set = set()\n",
    "        for i in range(len(instance)):\n",
    "            for j in range(1, len(instance[0])):\n",
    "                index_set.add((i, j))\n",
    "        prevepsilon = {}\n",
    "        while None in cleancells and index_set:\n",
    "            row, col = random.sample(index_set, 1)[0]\n",
    "            index_set.remove((row, col))\n",
    "            cleancells[row][col] = instance[row][col]\n",
    "            if col not in fds:\n",
    "                continue\n",
    "            epsilon = self.build_equiv_rel(cleancells, fds)\n",
    "            isclean = self.is_clean(cleancells, epsilon)\n",
    "            \n",
    "            if not isclean:\n",
    "                belonged_key = None\n",
    "                expected_values = set()\n",
    "                for key, value in prevepsilon[col].items():\n",
    "                    if row in value:\n",
    "                        belonged_key = key\n",
    "                        value.remove(row)\n",
    "                        while None in value:\n",
    "                            value.remove(None)\n",
    "                        expected_values = value\n",
    "                        break\n",
    "\n",
    "                if belonged_key == None:\n",
    "                    cleancells[row][col] = 'var' + str(no_of_val)\n",
    "                    no_of_val += 1\n",
    "                elif belonged_key == 'v0':\n",
    "                    if len(expected_values) >= 1:\n",
    "                        cleancells[row][col] = None\n",
    "                        while not cleancells[row][col] and len(expected_values) > 0:\n",
    "                            expected_row = expected_values.pop()\n",
    "                            cleancells[row][col] = cleancells[expected_row][col]\n",
    "                    else:\n",
    "                        cleancells[row][col] = 'var' + str(no_of_val)\n",
    "                        no_of_val += 1\n",
    "\n",
    "            epsilon = self.build_equiv_rel(cleancells, fds)\n",
    "            prevepsilon = epsilon\n",
    "            \n",
    "        cleancells_with_tuplieid = np.concatenate((instance[:,:1], cleancells[:,1:]), axis=1)\n",
    "        return cleancells_with_tuplieid\n",
    "    \n",
    "    def get_multiple_repairs(self, datas, fds, no_of_instances):\n",
    "        r_instances =  np.expand_dims(self.gen_repair(datas, fds), axis=0)\n",
    "        for i in range(1, no_of_instances):\n",
    "            repair = self.gen_repair(datas, fds)\n",
    "            r_instances = np.concatenate((r_instances, [repair]), axis=0)\n",
    "        return r_instances\n",
    "\n",
    "    def sample_tuple_from_repair_instances(self, tupleid, no_of_samples, r_instances):\n",
    "        sample_tuples = np.expand_dims(r_instances[np.random.randint(len(r_instances))][tupleid], axis=0)\n",
    "        for i in range(1, no_of_samples):\n",
    "            sample_tuple = r_instances[np.random.randint(len(r_instances))][tupleid]\n",
    "            sample_tuples = np.concatenate((sample_tuples, [sample_tuple]), axis=0)\n",
    "        return sample_tuples\n",
    "\n",
    "    def calc_prob(self, samples):\n",
    "        dicts = {}\n",
    "        for x in samples:\n",
    "            if x in samples:\n",
    "                index = -1\n",
    "                for i, val in enumerate(samples):\n",
    "                    if np.all(samples[i]==x):\n",
    "                        index = i\n",
    "                        break\n",
    "\n",
    "                if index not in dicts:\n",
    "                    dicts[index] = 1\n",
    "                else:\n",
    "                    dicts[index] += 1\n",
    "\n",
    "        output = []\n",
    "        n = len(samples)\n",
    "        for key in dicts:\n",
    "            amount = dicts[key]\n",
    "            new_tuple = np.concatenate((samples[key], [amount/n]), axis=0)\n",
    "            if len(output) == 0:\n",
    "                output = np.expand_dims(new_tuple, axis=0)\n",
    "            else:\n",
    "                output = np.concatenate((output, [new_tuple]), axis=0)\n",
    "        return output\n",
    "    \n",
    "    def get_probabilistic_samples(self, raw_data, fds, no_of_instances, no_of_samples):\n",
    "        repair_instances = self.get_multiple_repairs(raw_data, fds, no_of_instances)\n",
    "        samples = []\n",
    "        for tuple_id in np.squeeze(raw_data[:, :1], axis=1):\n",
    "            sample_tups = self.sample_tuple_from_repair_instances(int(tuple_id)-1, no_of_samples, repair_instances)\n",
    "            sample_tups_with_prob = self.calc_prob(sample_tups)\n",
    "            if len(samples) == 0:\n",
    "                samples = sample_tups_with_prob\n",
    "            else:\n",
    "                samples = np.concatenate((samples, sample_tups_with_prob), axis=0)\n",
    "        return samples\n",
    "\n",
    "data_from_file = np.loadtxt(\"income.train.txt.5k\", delimiter=',', dtype='str', encoding='utf-8-sig')\n",
    "ori_instance = data_from_file[:200]\n",
    "ori_instance = np.concatenate((np.expand_dims(range(1, len(ori_instance)+1), axis=1), ori_instance), axis=1)\n",
    "\n",
    "fds = np.array([[5,2]])\n",
    "ps = ProbabilisticSampling()\n",
    "\n",
    "no_of_instances = 10 #number of repair instances that we want to generate\n",
    "no_of_samples = 20 #number of samples used to calculate the probability\n",
    "start = time.time()\n",
    "probabilistic_samples = ps.get_probabilistic_samples(ori_instance, fds, no_of_instances, no_of_samples)\n",
    "print(\"running time:\", time.time() - start)\n",
    "np.savetxt(\"probabilistic_samples.csv\", probabilistic_samples, delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
